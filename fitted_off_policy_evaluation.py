"""
Created on December 12, 2018

@author: clvoloshin, 
"""

from fitted_algo import FittedAlgo
from model import Model
import numpy as np
from tqdm import tqdm

class FittedQEvaluation(FittedAlgo):
    def __init__(self, initial_states, num_inputs, dim_of_actions, max_epochs, gamma):
        '''
        An implementation of fitted Q iteration

        num_inputs: number of inputs
        dim_of_actions: dimension of action space
        max_epochs: positive int, specifies how many iterations to run the algorithm
        gamma: discount factor
        '''
        self.initial_states = initial_states
        super(FittedQEvaluation, self).__init__(num_inputs, dim_of_actions, max_epochs, gamma)

    def run(self, dataset, policy, epochs=3000, epsilon=1e-10, desc='FQE'):
        # dataset is the original dataset generated by pi_{old} to which we will find
        # an approximately optimal Q

        self.Q_k = self.init_Q()
        for k in tqdm(range(self.max_epochs), desc=desc):

            # {((x,a), r+gamma* Q(x',pi(x')))}
            x_prime = dataset['x_prime']
            
            if k == 0:
                # Q_0 = 0 everywhere
                costs = dataset['cost']
            else:
                costs = dataset['cost'] + (self.gamma*self.Q_k(x_prime, policy(x_prime)).reshape(-1)*(1-dataset['done'].astype(int))).reshape(-1)
            X_a = dataset['state_action']

            self.fit(X_a, costs, epochs=epochs, batch_size=X_a.shape[0], epsilon=epsilon, verbose=0)

        return np.mean([self.Q_k(state, policy(state)) for state in self.initial_states])
