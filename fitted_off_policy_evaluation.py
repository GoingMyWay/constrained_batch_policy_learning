"""
Created on December 12, 2018

@author: clvoloshin, 
"""

from fitted_algo import FittedAlgo
from model import Model
import numpy as np

class FittedQEvaluation(FittedAlgo):
	def __init__(self, initial_states, num_inputs, dim_of_actions, max_epochs, gamma):
		'''
		An implementation of fitted Q iteration

		num_inputs: number of inputs
		dim_of_actions: dimension of action space
		max_epochs: positive int, specifies how many iterations to run the algorithm
		gamma: discount factor
		'''
		self.initial_states = initial_states
		super(FittedQEvaluation, self).__init__(num_inputs, dim_of_actions, max_epochs, gamma)

	def run(self, dataset, policy):
		# dataset is the original dataset generated by pi_{old} to which we will find
		# an approximately optimal Q

		self.Q_k_minus_1 = self.init_Q()
		for k in range(self.max_epochs):

			# {((x,a), r+gamma* Q(x',pi(x')))}
			x_prime = dataset['x_prime']
			costs = dataset['cost'] + (self.gamma*self.Q_k(x_prime, policy(x_prime))).reshape(-1)
			X_a = dataset['state_action']

			self.fit(X_a, costs, epsilon=1e-8, verbose=1)
			self.Q_k.copy_over_to(self.Q_k_minus_1.model)

		import pdb; pdb.set_trace()
		return np.mean([self.Q_k(state, policy(state)) for state in self.initial_states])
